host: DESKTOP-ADLEJL2
Building DAG of jobs...
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job stats:
job             count
------------  -------
all                 1
create_first        2
total               3

Select jobs to execute...
Execute 1 jobs...

[Fri Dec 13 17:26:54 2024]
localrule create_first:
    input: user_input.xlsx, intermediate_data/small_seurat_102_obj.rds
    output: intermediate_data/filtered_small_seurat_102_obj.rds, filtered_small_seurat_102_obj.html, test_dir_102
    jobid: 3
    reason: Missing output files: intermediate_data/filtered_small_seurat_102_obj.rds
    wildcards: size=102
    resources: tmpdir=C:\Users\Danne\AppData\Local\Temp


        quarto render 2_second.qmd -P downsample_size=102           -output-dir test_dir_102           -o filtered_small_seurat_102_obj.html
        
[Fri Dec 13 17:27:07 2024]
Error in rule create_first:
    jobid: 3
    input: user_input.xlsx, intermediate_data/small_seurat_102_obj.rds
    output: intermediate_data/filtered_small_seurat_102_obj.rds, filtered_small_seurat_102_obj.html, test_dir_102
    shell:
        
        quarto render 2_second.qmd -P downsample_size=102           -output-dir test_dir_102           -o filtered_small_seurat_102_obj.html
        
        (one of the commands exited with non-zero exit code; note that snakemake uses bash strict mode!)

Shutting down, this might take some time.
Exiting because a job execution failed. Look above for error message
Complete log: .snakemake\log\2024-12-13T172654.074889.snakemake.log
WorkflowError:
At least one job did not complete successfully.
